{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirnaderiy/CNN_ViT/blob/main/ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvPK1zQZJ9Ve",
        "outputId": "d6ba3812-e9c1-421e-d513-73bf14b61ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/612.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWUj66kVKJ_H",
        "outputId": "b395231b-829c-48d3-80ec-e930481d006b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SztOclMZKl1u",
        "outputId": "f7d96089-3da7-4bce-dbbb-c3a5cf438a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gFe0-KXdNwbX"
      },
      "outputs": [],
      "source": [
        "data_directory = '/content/drive/My Drive/stylegan2/New folder (3)/'\n",
        "\n",
        "\n",
        "class_A_images = []\n",
        "class_B_images = []\n",
        "labels_A = []\n",
        "labels_B = []\n",
        "\n",
        "for class_name in os.listdir(data_directory):\n",
        "    class_path = os.path.join(data_directory, class_name)\n",
        "    if class_name == 'A':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            class_A_images.append(image)\n",
        "            labels_A.append(0)  # Class A label\n",
        "    elif class_name == 'B':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            class_B_images.append(image)\n",
        "            labels_B.append(1)  # Class B label\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data_A = np.array(class_A_images)\n",
        "data_B = np.array(class_B_images)\n",
        "labels_A = np.array(labels_A)\n",
        "labels_B = np.array(labels_B)\n",
        "\n",
        "# Combine data from both classes\n",
        "data = np.concatenate((data_A, data_B), axis=0)\n",
        "labels = np.concatenate((labels_A, labels_B), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_directory = '/content/drive/My Drive/stylegan2/Test/'\n",
        "\n",
        "\n",
        "test_A_images = []\n",
        "test_B_images = []\n",
        "testlabels_A = []\n",
        "testlabels_B = []\n",
        "\n",
        "for class_name in os.listdir(test_directory):\n",
        "    class_path = os.path.join(test_directory, class_name)\n",
        "    if class_name == 'A':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            test_A_images.append(image)\n",
        "            testlabels_A.append(0)  # Class A label\n",
        "    elif class_name == 'B':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            test_B_images.append(image)\n",
        "            testlabels_B.append(1)  # Class B label\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "testdata_A = np.array(test_A_images)\n",
        "testdata_B = np.array(test_B_images)\n",
        "testlabels_A = np.array(testlabels_A)\n",
        "testlabels_B = np.array(testlabels_B)\n",
        "\n",
        "# Combine data from both classes\n",
        "test_data = np.concatenate((testdata_A, testdata_B), axis=0)\n",
        "test_labels = np.concatenate((testlabels_A, testlabels_B), axis=0)"
      ],
      "metadata": {
        "id": "UsYeb8ybXL01"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_directory = '/content/drive/My Drive/stylegan2/valid/'\n",
        "\n",
        "\n",
        "valid_A_images = []\n",
        "valid_B_images = []\n",
        "validlabels_A = []\n",
        "validlabels_B = []\n",
        "\n",
        "for class_name in os.listdir(valid_directory):\n",
        "    class_path = os.path.join(valid_directory, class_name)\n",
        "    if class_name == 'A':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            valid_A_images.append(image)\n",
        "            validlabels_A.append(0)  # Class A label\n",
        "    elif class_name == 'B':\n",
        "        for image_filename in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_filename)\n",
        "            image = load_img(image_path, target_size=(224, 224))\n",
        "            image = img_to_array(image)\n",
        "            valid_B_images.append(image)\n",
        "            validlabels_B.append(1)  # Class B label\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "validdata_A = np.array(valid_A_images)\n",
        "validdata_B = np.array(valid_B_images)\n",
        "validlabels_A = np.array(validlabels_A)\n",
        "validlabels_B = np.array(validlabels_B)\n",
        "\n",
        "# Combine data from both classes\n",
        "valid_data = np.concatenate((validdata_A, validdata_B), axis=0)\n",
        "valid_labels = np.concatenate((validlabels_A, validlabels_B), axis=0)"
      ],
      "metadata": {
        "id": "EfFZkwi6mGSv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icJK1ohTKvef",
        "outputId": "a8b2d3a6-9d2d-4759-e1ae-b71bfd8d2099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "15/15 [==============================] - 25s 671ms/step - loss: 16.5989 - accuracy: 0.6511 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 2/120\n",
            "15/15 [==============================] - 9s 632ms/step - loss: 6.2475 - accuracy: 0.6267 - val_loss: 8.7505 - val_accuracy: 0.4000\n",
            "Epoch 3/120\n",
            "15/15 [==============================] - 3s 210ms/step - loss: 2.7210 - accuracy: 0.7133 - val_loss: 0.4494 - val_accuracy: 0.8200\n",
            "Epoch 4/120\n",
            "15/15 [==============================] - 10s 709ms/step - loss: 1.4339 - accuracy: 0.7667 - val_loss: 0.4709 - val_accuracy: 0.8400\n",
            "Epoch 5/120\n",
            "15/15 [==============================] - 4s 272ms/step - loss: 1.3407 - accuracy: 0.7778 - val_loss: 0.0398 - val_accuracy: 0.9600\n",
            "Epoch 6/120\n",
            "15/15 [==============================] - 9s 611ms/step - loss: 1.1458 - accuracy: 0.7867 - val_loss: 0.0630 - val_accuracy: 0.9600\n",
            "Epoch 7/120\n",
            "15/15 [==============================] - 12s 820ms/step - loss: 0.8867 - accuracy: 0.8489 - val_loss: 0.5688 - val_accuracy: 0.8200\n",
            "Epoch 8/120\n",
            "15/15 [==============================] - 6s 410ms/step - loss: 0.7244 - accuracy: 0.8422 - val_loss: 0.1117 - val_accuracy: 0.9600\n",
            "Epoch 9/120\n",
            "15/15 [==============================] - 8s 590ms/step - loss: 0.4688 - accuracy: 0.8800 - val_loss: 1.0003 - val_accuracy: 0.7600\n",
            "Epoch 10/120\n",
            "15/15 [==============================] - 11s 757ms/step - loss: 0.5818 - accuracy: 0.8533 - val_loss: 0.2962 - val_accuracy: 0.9600\n",
            "Epoch 11/120\n",
            "15/15 [==============================] - 12s 831ms/step - loss: 0.3519 - accuracy: 0.8844 - val_loss: 0.1353 - val_accuracy: 0.9600\n",
            "Epoch 12/120\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.2804 - accuracy: 0.9089 - val_loss: 0.3340 - val_accuracy: 0.9000\n",
            "Epoch 13/120\n",
            "15/15 [==============================] - 10s 732ms/step - loss: 0.2972 - accuracy: 0.9356 - val_loss: 0.0483 - val_accuracy: 0.9600\n",
            "Epoch 14/120\n",
            "15/15 [==============================] - 8s 565ms/step - loss: 0.2539 - accuracy: 0.9222 - val_loss: 0.1654 - val_accuracy: 0.9600\n",
            "Epoch 15/120\n",
            "15/15 [==============================] - 6s 424ms/step - loss: 0.1879 - accuracy: 0.9400 - val_loss: 0.0845 - val_accuracy: 0.9600\n",
            "Epoch 16/120\n",
            "15/15 [==============================] - 12s 824ms/step - loss: 0.1849 - accuracy: 0.9467 - val_loss: 0.0567 - val_accuracy: 0.9600\n",
            "Epoch 17/120\n",
            "15/15 [==============================] - 9s 668ms/step - loss: 0.2577 - accuracy: 0.8911 - val_loss: 0.0698 - val_accuracy: 0.9600\n",
            "Epoch 18/120\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 0.1358 - accuracy: 0.9422 - val_loss: 0.0775 - val_accuracy: 0.9600\n",
            "Epoch 19/120\n",
            "15/15 [==============================] - 10s 699ms/step - loss: 0.0844 - accuracy: 0.9778 - val_loss: 0.0476 - val_accuracy: 0.9600\n",
            "Epoch 20/120\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.0361 - val_accuracy: 0.9600\n",
            "Epoch 21/120\n",
            "15/15 [==============================] - 11s 751ms/step - loss: 0.0906 - accuracy: 0.9711 - val_loss: 0.0287 - val_accuracy: 0.9800\n",
            "Epoch 22/120\n",
            "15/15 [==============================] - 11s 747ms/step - loss: 0.1295 - accuracy: 0.9600 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 23/120\n",
            "15/15 [==============================] - 5s 372ms/step - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 24/120\n",
            "15/15 [==============================] - 8s 580ms/step - loss: 0.1199 - accuracy: 0.9756 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 25/120\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.0916 - accuracy: 0.9689 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 26/120\n",
            "15/15 [==============================] - 10s 690ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 27/120\n",
            "15/15 [==============================] - 9s 622ms/step - loss: 0.0891 - accuracy: 0.9733 - val_loss: 3.2017e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/120\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0802 - accuracy: 0.9667 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 29/120\n",
            "15/15 [==============================] - 11s 764ms/step - loss: 0.0829 - accuracy: 0.9644 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 30/120\n",
            "15/15 [==============================] - 6s 387ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 31/120\n",
            "15/15 [==============================] - 8s 539ms/step - loss: 0.0449 - accuracy: 0.9822 - val_loss: 6.1864e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/120\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0546 - accuracy: 0.9711 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 33/120\n",
            "15/15 [==============================] - 10s 696ms/step - loss: 0.0314 - accuracy: 0.9844 - val_loss: 3.3327e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/120\n",
            "15/15 [==============================] - 3s 218ms/step - loss: 0.0284 - accuracy: 0.9844 - val_loss: 2.7006e-05 - val_accuracy: 1.0000\n",
            "Epoch 35/120\n",
            "15/15 [==============================] - 10s 706ms/step - loss: 0.0148 - accuracy: 0.9911 - val_loss: 9.0052e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/120\n",
            "15/15 [==============================] - 3s 224ms/step - loss: 0.0546 - accuracy: 0.9867 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 37/120\n",
            "15/15 [==============================] - 10s 693ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 38/120\n",
            "15/15 [==============================] - 10s 689ms/step - loss: 0.0705 - accuracy: 0.9689 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 39/120\n",
            "15/15 [==============================] - 5s 339ms/step - loss: 0.1124 - accuracy: 0.9756 - val_loss: 0.1150 - val_accuracy: 0.9600\n",
            "Epoch 40/120\n",
            "15/15 [==============================] - 10s 678ms/step - loss: 0.0549 - accuracy: 0.9756 - val_loss: 0.0271 - val_accuracy: 0.9800\n",
            "Epoch 41/120\n",
            "15/15 [==============================] - 12s 831ms/step - loss: 0.0808 - accuracy: 0.9733 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 42/120\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.0747 - accuracy: 0.9800 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 43/120\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0687 - accuracy: 0.9822 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 44/120\n",
            "15/15 [==============================] - 8s 577ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 1.1649e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/120\n",
            "15/15 [==============================] - 12s 824ms/step - loss: 0.0445 - accuracy: 0.9911 - val_loss: 2.9851e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/120\n",
            "15/15 [==============================] - 9s 658ms/step - loss: 0.0495 - accuracy: 0.9822 - val_loss: 4.5318e-05 - val_accuracy: 1.0000\n",
            "Epoch 47/120\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.1334 - accuracy: 0.9622 - val_loss: 3.3379e-08 - val_accuracy: 1.0000\n",
            "Epoch 48/120\n",
            "15/15 [==============================] - 9s 646ms/step - loss: 0.0538 - accuracy: 0.9844 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 49/120\n",
            "15/15 [==============================] - 3s 213ms/step - loss: 0.0959 - accuracy: 0.9822 - val_loss: 8.1636e-05 - val_accuracy: 1.0000\n",
            "Epoch 50/120\n",
            "15/15 [==============================] - 8s 596ms/step - loss: 0.1495 - accuracy: 0.9733 - val_loss: 2.3303e-05 - val_accuracy: 1.0000\n",
            "Epoch 51/120\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0423 - accuracy: 0.9800 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
            "Epoch 52/120\n",
            "15/15 [==============================] - 8s 547ms/step - loss: 0.0825 - accuracy: 0.9800 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 53/120\n",
            "15/15 [==============================] - 12s 830ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 9.9062e-05 - val_accuracy: 1.0000\n",
            "Epoch 54/120\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 0.0824 - accuracy: 0.9800 - val_loss: 3.0801e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/120\n",
            "15/15 [==============================] - 11s 767ms/step - loss: 0.0726 - accuracy: 0.9756 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
            "Epoch 56/120\n",
            "15/15 [==============================] - 8s 586ms/step - loss: 0.1010 - accuracy: 0.9800 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 57/120\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.1283 - accuracy: 0.9578 - val_loss: 4.3987e-06 - val_accuracy: 1.0000\n",
            "Epoch 58/120\n",
            "15/15 [==============================] - 12s 819ms/step - loss: 0.1016 - accuracy: 0.9800 - val_loss: 1.8954e-06 - val_accuracy: 1.0000\n",
            "Epoch 59/120\n",
            "15/15 [==============================] - 13s 906ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
            "Epoch 60/120\n",
            "15/15 [==============================] - 3s 206ms/step - loss: 0.0615 - accuracy: 0.9822 - val_loss: 3.2320e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/120\n",
            "15/15 [==============================] - 11s 769ms/step - loss: 0.0377 - accuracy: 0.9867 - val_loss: 3.5763e-08 - val_accuracy: 1.0000\n",
            "Epoch 62/120\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
            "Epoch 63/120\n",
            "15/15 [==============================] - 7s 465ms/step - loss: 0.0270 - accuracy: 0.9956 - val_loss: 1.6355e-06 - val_accuracy: 1.0000\n",
            "Epoch 64/120\n",
            "15/15 [==============================] - 4s 296ms/step - loss: 0.0276 - accuracy: 0.9889 - val_loss: 3.0857e-05 - val_accuracy: 1.0000\n",
            "Epoch 65/120\n",
            "15/15 [==============================] - 9s 651ms/step - loss: 0.0085 - accuracy: 0.9956 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
            "Epoch 66/120\n",
            "15/15 [==============================] - 12s 827ms/step - loss: 0.0314 - accuracy: 0.9911 - val_loss: 2.3842e-09 - val_accuracy: 1.0000\n",
            "Epoch 67/120\n",
            "15/15 [==============================] - 12s 818ms/step - loss: 0.0293 - accuracy: 0.9956 - val_loss: 3.6621e-06 - val_accuracy: 1.0000\n",
            "Epoch 68/120\n",
            "15/15 [==============================] - 7s 471ms/step - loss: 0.0181 - accuracy: 0.9911 - val_loss: 7.6055e-07 - val_accuracy: 1.0000\n",
            "Epoch 69/120\n",
            "15/15 [==============================] - 8s 576ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 1.7693e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/120\n",
            "15/15 [==============================] - 10s 702ms/step - loss: 0.0120 - accuracy: 0.9956 - val_loss: 5.7220e-08 - val_accuracy: 1.0000\n",
            "Epoch 71/120\n",
            "15/15 [==============================] - 3s 221ms/step - loss: 0.0228 - accuracy: 0.9956 - val_loss: 1.8791e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/120\n",
            "15/15 [==============================] - 9s 643ms/step - loss: 0.0090 - accuracy: 0.9956 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
            "Epoch 73/120\n",
            "15/15 [==============================] - 8s 565ms/step - loss: 0.0044 - accuracy: 0.9978 - val_loss: 2.3842e-08 - val_accuracy: 1.0000\n",
            "Epoch 74/120\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
            "Epoch 75/120\n",
            "15/15 [==============================] - 8s 550ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 1.6450e-06 - val_accuracy: 1.0000\n",
            "Epoch 76/120\n",
            "15/15 [==============================] - 9s 632ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 4.7684e-09 - val_accuracy: 1.0000\n",
            "Epoch 77/120\n",
            "15/15 [==============================] - 7s 470ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 4.0054e-07 - val_accuracy: 1.0000\n",
            "Epoch 78/120\n",
            "15/15 [==============================] - 7s 524ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 3.1519e-06 - val_accuracy: 1.0000\n",
            "Epoch 79/120\n",
            "15/15 [==============================] - 9s 649ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 5.8174e-07 - val_accuracy: 1.0000\n",
            "Epoch 80/120\n",
            "15/15 [==============================] - 7s 495ms/step - loss: 0.0264 - accuracy: 0.9956 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
            "Epoch 81/120\n",
            "15/15 [==============================] - 12s 831ms/step - loss: 0.0165 - accuracy: 0.9978 - val_loss: 1.1921e-08 - val_accuracy: 1.0000\n",
            "Epoch 82/120\n",
            "15/15 [==============================] - 9s 658ms/step - loss: 0.0029 - accuracy: 0.9978 - val_loss: 4.7684e-08 - val_accuracy: 1.0000\n",
            "Epoch 83/120\n",
            "15/15 [==============================] - 5s 345ms/step - loss: 7.6804e-04 - accuracy: 1.0000 - val_loss: 1.0252e-07 - val_accuracy: 1.0000\n",
            "Epoch 84/120\n",
            "15/15 [==============================] - 9s 622ms/step - loss: 0.0081 - accuracy: 0.9956 - val_loss: 5.9077e-06 - val_accuracy: 1.0000\n",
            "Epoch 85/120\n",
            "15/15 [==============================] - 3s 229ms/step - loss: 0.0034 - accuracy: 0.9978 - val_loss: 1.1611e-06 - val_accuracy: 1.0000\n",
            "Epoch 86/120\n",
            "15/15 [==============================] - 8s 578ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 2.3147e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/120\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 3.2689e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/120\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 4.2015e-04 - accuracy: 1.0000 - val_loss: 8.1479e-06 - val_accuracy: 1.0000\n",
            "Epoch 89/120\n",
            "15/15 [==============================] - 9s 644ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 2.7075e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/120\n",
            "15/15 [==============================] - 9s 637ms/step - loss: 0.0031 - accuracy: 0.9978 - val_loss: 1.1340e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/120\n",
            "15/15 [==============================] - 8s 544ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.2838e-06 - val_accuracy: 1.0000\n",
            "Epoch 92/120\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5282e-06 - val_accuracy: 1.0000\n",
            "Epoch 93/120\n",
            "15/15 [==============================] - 11s 768ms/step - loss: 0.0769 - accuracy: 0.9867 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 94/120\n",
            "15/15 [==============================] - 3s 212ms/step - loss: 0.1130 - accuracy: 0.9711 - val_loss: 1.2875e-07 - val_accuracy: 1.0000\n",
            "Epoch 95/120\n",
            "15/15 [==============================] - 11s 764ms/step - loss: 0.1792 - accuracy: 0.9711 - val_loss: 1.3233e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/120\n",
            "15/15 [==============================] - 12s 833ms/step - loss: 0.0760 - accuracy: 0.9778 - val_loss: 7.1106e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/120\n",
            "15/15 [==============================] - 5s 382ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 5.3927e-06 - val_accuracy: 1.0000\n",
            "Epoch 98/120\n",
            "15/15 [==============================] - 9s 610ms/step - loss: 0.0175 - accuracy: 0.9911 - val_loss: 0.1085 - val_accuracy: 0.9600\n",
            "Epoch 99/120\n",
            "15/15 [==============================] - 5s 383ms/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 1.3590e-07 - val_accuracy: 1.0000\n",
            "Epoch 100/120\n",
            "15/15 [==============================] - 9s 645ms/step - loss: 0.0747 - accuracy: 0.9778 - val_loss: 2.0524e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/120\n",
            "15/15 [==============================] - 10s 674ms/step - loss: 0.0926 - accuracy: 0.9889 - val_loss: 5.1120e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/120\n",
            "15/15 [==============================] - 12s 832ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 2.4246e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/120\n",
            "15/15 [==============================] - 7s 473ms/step - loss: 0.0601 - accuracy: 0.9844 - val_loss: 6.8304e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/120\n",
            "15/15 [==============================] - 8s 542ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 5.2947e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/120\n",
            "15/15 [==============================] - 12s 817ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
            "Epoch 106/120\n",
            "15/15 [==============================] - 5s 334ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 7.3910e-08 - val_accuracy: 1.0000\n",
            "Epoch 107/120\n",
            "15/15 [==============================] - 9s 607ms/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 2.7227e-06 - val_accuracy: 1.0000\n",
            "Epoch 108/120\n",
            "15/15 [==============================] - 12s 816ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 4.6990e-06 - val_accuracy: 1.0000\n",
            "Epoch 109/120\n",
            "15/15 [==============================] - 9s 631ms/step - loss: 0.0089 - accuracy: 0.9956 - val_loss: 1.1080e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/120\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0124 - accuracy: 0.9933 - val_loss: 1.4281e-05 - val_accuracy: 1.0000\n",
            "Epoch 111/120\n",
            "15/15 [==============================] - 8s 571ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3446e-06 - val_accuracy: 1.0000\n",
            "Epoch 112/120\n",
            "15/15 [==============================] - 5s 362ms/step - loss: 0.0232 - accuracy: 0.9978 - val_loss: 8.9736e-05 - val_accuracy: 1.0000\n",
            "Epoch 113/120\n",
            "15/15 [==============================] - 10s 700ms/step - loss: 0.0288 - accuracy: 0.9867 - val_loss: 4.6894e-06 - val_accuracy: 1.0000\n",
            "Epoch 114/120\n",
            "15/15 [==============================] - 3s 211ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
            "Epoch 115/120\n",
            "15/15 [==============================] - 10s 697ms/step - loss: 0.0099 - accuracy: 0.9956 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 116/120\n",
            "15/15 [==============================] - 10s 693ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 4.7445e-07 - val_accuracy: 1.0000\n",
            "Epoch 117/120\n",
            "15/15 [==============================] - 4s 300ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
            "Epoch 118/120\n",
            "15/15 [==============================] - 11s 761ms/step - loss: 5.8528e-04 - accuracy: 1.0000 - val_loss: 2.1458e-08 - val_accuracy: 1.0000\n",
            "Epoch 119/120\n",
            "15/15 [==============================] - 9s 653ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.2636e-07 - val_accuracy: 1.0000\n",
            "Epoch 120/120\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.1526e-09 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 1s 147ms/step - loss: 6.3468 - accuracy: 0.4400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.346757411956787, 0.4399999976158142]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "input_shape = (120, 120, 3)\n",
        "\n",
        "\n",
        "# Configure the hyperparameters\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "num_epochs = 120\n",
        "image_size = 120 # We'll resize input images to this size\n",
        "patch_size = 6 # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "] # Size of the transformer layers\n",
        "transformer_layers = 4\n",
        "mlp_head_units = [2048, 1024] # Size of the dense layers of the final classifier\n",
        "\n",
        "# Use data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),  # Match the input size to image_size\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "\n",
        "\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(data)\n",
        "\n",
        "# Implement multilayer perceptron (MLP)\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "# Implement patch creation as a layer\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "# Implement the patch encoding layer\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "# Build the ViT model\n",
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        "\n",
        "# Compile the model\n",
        "model = create_vit_classifier()\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    ),\n",
        "    metrics=[\n",
        "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "data_resized = tf.image.resize(data, (120, 120))\n",
        "history = model.fit(\n",
        "    x=data_resized,\n",
        "    y=labels,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=(valid_data, valid_labels),\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng35KPzWiqxZ",
        "outputId": "56bcfdd4-19ba-4c1a-89db-6b75b884fb4f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 362ms/step - loss: 6.3468 - accuracy: 0.4400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.346757411956787, 0.4399999976158142]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmZeJiuGXyriUndXTYPn1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}